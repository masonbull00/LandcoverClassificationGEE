  ///////////////////////////////////////////////////////////
 /////////////LET'S CLASSIFY SOME IMAGES////////////////////
/////////////////////////////////////////////////////////// 

////////////////////////////////////////////////////////////
//This script performs a landcover classification of Landsat data 
//Training data for the model is what you may have created in a previous code
//You will need:
    //a feature or feature collection that is the watershed boundary
    //an outline of stable water bodies in the watershed (optional, but aids in classification)
    //training data of your landcover classes for your watershed
    //a working understanding of basic remote sensing concepts 
//To keep things concise in the script, it is helpful to have this script copied for each satellite you are 
//working with
//This is where the magic happens! :)//


//////////////////////////////////////////////////////////////
//Common errors in this script come from imagery being masked out entirely
////and not having bands. This is fine, there jsut won't be an image for that year.
//Most errors are not fatal in this script and it will continue to run.
//Play around with what years to allow imagery to come from to see if you fix errors


//You are going to notice a lot of similarities between this and the training data script
//This is by design to maintain continuity between TD and classified imagery

//start by adding in your training data, watershed boundary, and water polygon assets as imports 
//the default naming convention is: classes, watershed, and water, respectively.
//Any reference to NJ is Nellie Juan, for posterity

//Here we are setting the map center over the study area
Map.setCenter(-148.88725, 60.35079, 11); //<-- lat lon of study area and zoom level 
Map.setOptions({mapTypeId: 'HYBRID'}); // <- sets the baselayer to satellite imagery with labels

// Add ROI and set your date to find imagery
var roi = ee.Geometry.Point(-148.921745, 60.379588); //<-- Wolverine Glacier
var date_i = '1984-03-01'; //<- you will need start and end times for filtering imagery, set initial date (YYYY-MM-DD)
var date_f = '2022-10-31'; // Set final date (YYY-MM-DD)

//add an outline of the Nellie Juan Watershed to visualize the study area
var styling = {color: 'black', width: 4, fillColor: 'FF000000'}; //<- create a black outline of the study area
Map.addLayer(watershed.style(styling), null, 'nj_wtrshd');// <- add the outline to the map



///////////////////////////////////////////////////////////////
///////////Landsat 8 Workflow for the Nellie Juan//////////////
///////////////////////////////////////////////////////////////


// add landsat imagery, filter by cloud cover over land, only select spectral bands, and filter by roi and specified date range
var l8 = ee.ImageCollection("LANDSAT/LC08/C02/T1_L2") //<- Landsat 8 Surface Reflectance Data
  .filterDate(date_i, date_f) // <- filter the date range to the input start and end
  .filter(ee.Filter.calendarRange(8, 10, 'month')) //<- filter by months to get a specific season
  .filterBounds(roi) //<- filter the collection by your study area (DO NOT LEAVE THIS BLANK)
  .select( 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'QA_PIXEL') //<- selecting the bands we want to use, these are all spectral and a wuality assurance band
  .filter(ee.Filter.lte('CLOUD_COVER_LAND', 25)); //<- only take images with less than X% cloud cover
print('l8', l8); //<- print to the console to make sure it worked

var l8Proj = l8.first().projection();// <- this gives you the projection of the data for georeferencing later

//this applies a QA bitmask to filter out pixels with excessive clouds and shadows
//this function is adapted from Spatial Thoughts: https://spatialthoughts.com/2021/08/19/qa-bands-bitmasks-gee/
var qaFunc = function(image){
  var bitwiseExtract = function(input, fromBit, toBit) {
    var maskSize = ee.Number(1).add(toBit).subtract(fromBit);//<- apply a bitmask to QA bands for various data inputs
    var mask = ee.Number(1).leftShift(maskSize).subtract(1);
    return input.rightShift(fromBit).bitwiseAnd(mask);
  };

  var qaBand = image.select('QA_PIXEL'); //<- call the QA band for referencing
  var cirrus = bitwiseExtract(qaBand, 14, 15).neq(3);
  var cloud = bitwiseExtract(qaBand, 8, 9).neq(3); //<- these are various QA bands in Landsat imagery, read more about them in the data docs
  var bitMask = cirrus.and(cloud);
  return image.mask(bitMask);
};

var l8cloudFree = l8.map(qaFunc); //<- map the QA function over the Landsat Image Collection
print('l8 cloud free', l8cloudFree);

var checkCRS = l8.first().projection().crs(); //<- check and print the CRS you are working in, optional but sometimes helpful if your stuck
//print('l8 crs', checkCRS); //<- comment out if you don't need this information

var pxCount = l8.first().reduceRegion({
  reducer: ee.Reducer.count(),// <- this gives you a count of how many pixels are in the watershed, also optional
  geometry: watershed.geometry()
});
//print('pixel count', pxCount); //<- comment out if you don't need this information

//add a visualization parameter for the landsat imagery to display in the map if wanted
var l8visParams = {bands: ['B4', 'B3', 'B2'], min:0, max: 18000, gamma: [1,1,1]}; //<- play with min max values to adjust brightness, also
                                                                                  //can be done in map viewer manually

//add SRTM data, clip it to the the Nellie Juan, select only the elevation band, and then derive slope and aspect as separate images
var DEM = ee.Image("NASA/NASADEM_HGT/001").clip(watershed.geometry()).select('elevation').reproject(l8Proj);
var slope = ee.Terrain.slope(DEM);
var aspect = ee.Terrain.aspect(DEM);
//print('Elevation', DEM);
//print('Slope', slope);
//print('Aspect', aspect);


//export DEM data if needed
//Export.image.toDrive({            -------------
//  image: DEM,                                 |  
//  description: 'NJ_Elevation',                |
//  folder: 'TopoImagery',                      |
//  fileNamePrefix: 'NJ_Elevation',             |
//  scale: 30,                                  |<- Export Elevation data if you want it  
//  maxPixels: 9e7,                             | 
//  fileFormat: 'GeoTIFF',                      |
//  region: watershed.geometry(),               |
//  crs: 'EPSG:32606'});            -------------            
//Export.image.toDrive({           -------------- 
//  image: slope,                               |
//  description: 'NJ_Slope',                    |
//  folder: 'TopoImagery',                      |
//  fileNamePrefix: 'NJ_Slope',                 |
//  scale: 30,                                  |<- slope data Export
//  maxPixels: 9e7,                             |
//  fileFormat: 'GeoTIFF',                      |
//  region: watershed.geometry(),               |
//  crs: 'EPSG:32606'});            -------------
//Export.image.toDrive({          ---------------
//  image: aspect,                              |
//  description: 'NJ_Aspect',                   |
//  folder: 'TopoImagery',                      |
//  fileNamePrefix: 'NJ_Aspect',                |
//  scale: 30,                                  |<- aspect data export
//  maxPixels: 9e7,                             |
//  fileFormat: 'GeoTIFF',                      |
//  region: watershed.geometry(),               |
//  crs: 'EPSG:32606'});          --------------- <- be sure to alter your EPSG to wherever your watershed is for each image!!!!!

var demClip = watershed; //<- set up clipping area (watershed boundary) for future functions

var oliBands = ['SR_B2',   'SR_B3',    'SR_B4',  'SR_B5',  'SR_B6', 'SR_B7'];//<- define bands for Landsat 8
var tmEtmBands = ['SR_B1',   'SR_B2',    'SR_B3',  'SR_B4',  'SR_B5', 'SR_B7'];//<- define bands for Landsat 5/7
var defBands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2'];//<- dictionary of bands for renaming in later steps

var l8cor = l8cloudFree.select(oliBands, defBands); //<- define bands. In this case, Landsat 8, alter if using another sensor
//print('l8cor', l8cor);// <- print to check that renaming worked (optional)

//This is the meat of the topographic correction
//We are using SCS+C algorith (Soenen et al., 2005). Code adapted from Spatial Thoughts Geo Blog

//function to compute radians from degrees
function radians(img) {
  return img.toFloat().multiply(Math.PI).divide(180);}
//Get DEM Slope and Aspect in radians
var SLPrads = radians(slope);
var ASPrads = radians(aspect);

//function to do the terrain correction
var scscTCl8 = function(img) {
  var outImage = img.select([]);
  
  //Get the footprint image of the study area
  var footprint = ee.Geometry.Polygon(ee.Number(ee.List(img.get('system:footprint'))));

  //VARIABLES FROM METADATA
  var AZ = ee.Number(img.get('SUN_AZIMUTH'));
  var ZE = ee.Number(img.get('SUN_ELEVATION'));
  var AZ_R = radians(ee.Image(AZ));
  var ZE_R = radians(ee.Image(ZE));
  
  //CALCULATE LOCAL ILLUMINATION, COS OF THE SLOPE, AND COS OF THE ZENITH ANGLE
  var IL = AZ_R.subtract(ASPrads).cos().multiply(SLPrads.sin()).multiply(ZE_R.sin())
  .add(ZE_R.cos().multiply(SLPrads.cos()));
  var cos_ZE = ZE_R.cos();
  var cos_SLP = SLPrads.cos();
  

  //C for the blue band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultBlue = clippedImg.select('constant', 'constant_1', 'blue')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var blueC = (ee.Array(resultBlue.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultBlue.get('coefficients')).get([1,0]));
  var blueCorr = ((cos_ZE.multiply(cos_SLP)).add(blueC)).divide(IL.add(blueC));

  
  //C for the green band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultGreen = clippedImg.select('constant', 'constant_1', 'green')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var greenC = (ee.Array(resultGreen.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultGreen.get('coefficients')).get([1,0]));
  var greenCorr = ((cos_ZE.multiply(cos_SLP)).add(greenC)).divide(IL.add(greenC));
  
  //C for the red band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultRed = clippedImg.select('constant', 'constant_1', 'red')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var redC = (ee.Array(resultRed.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultRed.get('coefficients')).get([1,0]));
  var redCorr = ((cos_ZE.multiply(cos_SLP)).add(redC)).divide(IL.add(redC));
  
  //C for the nir band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultNir = clippedImg.select('constant', 'constant_1', 'nir')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var nirC = (ee.Array(resultNir.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultNir.get('coefficients')).get([1,0]));
  var nirCorr = ((cos_ZE.multiply(cos_SLP)).add(nirC)).divide(IL.add(nirC));
  
  //C for the swir1 band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultSwir1 = clippedImg.select('constant', 'constant_1', 'swir1')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var swir1C = (ee.Array(resultSwir1.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultSwir1.get('coefficients')).get([1,0]));
  var swir1Corr = ((cos_ZE.multiply(cos_SLP)).add(swir1C)).divide(IL.add(swir1C));
  
  //C for the swir2 band
  var clippedImg = img.addBands(1).addBands(IL);
  var resultSwir2 = clippedImg.select('constant', 'constant_1', 'swir2')
    .reduceRegion({
      reducer: ee.Reducer.linearRegression(2,1),
      geometry: footprint,
      scale: 30,
      maxPixels: 2e9
      });
  var swir2C = (ee.Array(resultSwir2.get('coefficients')).get([0,0]))
  .divide(ee.Array(resultSwir2.get('coefficients')).get([1,0]));
  var swir2Corr = ((cos_ZE.multiply(cos_SLP)).add(swir2C)).divide(IL.add(swir2C));
  
  //IMAGE CORRECTION
  var InImg2 = img.multiply(0.0001);
  
  var blueBand = InImg2.select('blue').multiply(blueCorr);
  //Map.addLayer(blueBand);
  var greenBand = InImg2.select('green').multiply(greenCorr);
  var redBand = InImg2.select('red').multiply(redCorr);
  var nirBand = InImg2.select('nir').multiply(redCorr);
  var swir1Band = InImg2.select('swir1').multiply(swir1Corr);
  var swir2Band = InImg2.select('swir2').multiply(swir2Corr);
  
  var img_TC = img.select().addBands([blueBand, greenBand, redBand, nirBand, swir1Band, swir2Band]);
  //print('img_TC', img_TC)
  
  //ADJUST VALUE RANGE (REFLECTANCE BETWEEN 0 AND 1)
  var img_TC1 = ((img_TC.multiply(10000)).int16());//.multiply(0.0001);
    
  outImage = outImage.addBands(img_TC1
  .select([0,1,2,3,4,5],['blue_TC', 'green_TC', 'red_TC', 'nir_TC', 'swir1_TC', 'swir2_TC']));
  return outImage;
};

var l8corCol = l8cor.map(scscTCl8);//<- map the topo. correction over your image collection
print('l8 corrected col', l8corCol);

var renameBands = function(image){//<- rename the bands in the new imagery to make them shorter
  return image.select(['blue_TC', 'green_TC', 'red_TC', 'nir_TC', 'swir1_TC', 'swir2_TC'])//<- make sure you know your bands and what they are!!
  .rename(['B2', 'B3', 'B4', 'B5', 'B6', 'B7']); //<- Don't mix up your sensors! Reference List: https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites
};

var l8renamed = l8corCol.map(renameBands); //<- Map renaming function over image collection
//print('RENAMED L8', l8renamed);

// create a function to clip each image in the image collection to the Nellie Juan
var clipping = function(image) {
  return image.clip(watershed); //<- clip all of the imagery to the study area
};

// Apply clipping function to l8 data
var l8_clip = l8renamed.map(clipping); //<- map your clipping function over imagery
//print('l8 clipped', l8_clip);

// create a function to add the DEM elevation, slope, and aspect bands to the landsat images
var addDEM = function(image){
  return image.addBands(DEM).addBands(slope).addBands(aspect);
};

//apply the addDEM function to each image in the collection
var l8DEM = l8_clip.map(addDEM);
//print('l8 + DEM', l8DEM);

//create a water mask using NHD waterbodies polygons
var njWaterImg = water.reduceToImage(['fid'], ee.Reducer.sum()).clip(watershed.geometry()); //<- reduce polygons to a raster format
var mask = njWaterImg.select('sum').neq(0); //<- create a mask of water polygons
var waterMask = mask.not(); //<- invert the mask so that it is in the correct format
//print('Water Mask', waterMask);

//create a function to apply the water mask to the composited imagery
var applyMask = function(image){
  return image.updateMask(waterMask);
};

//apply the water masking function to the composited imagery
var l8Masked = l8DEM.map(applyMask); //<- I found water to be detrimental to classification, get rid of it! (unless you're classifying water...)
print('Masked L8 Imagery', l8Masked);

//create a function to generate an NDSI, NDVI and EVI on the imagery
var createNDSI = function(image){
  var NDSI = image.normalizedDifference(['B3', 'B6']).rename('NDSI'); //<- Normalized Difference Snow Index
  var NDVI = image.normalizedDifference(['B5', 'B4']).rename('NDVI'); //<- Normalized Difference Vegetation Index
  var EVI = image.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',{
    'NIR' : image.select('B5').multiply(0.0000275).add(-0.2),
    'RED' : image.select('B4').multiply(0.0000275).add(-0.2), //<^- quick and dirty Enhanced Vegetation Index
    'BLUE' : image.select('B2').multiply(0.0000275).add(-0.2)
  }).rename('EVI');
  return image.addBands(NDSI).addBands(NDVI).addBands(EVI);
};

//apply the NDSI and NDVI creation function to the imagery
var l8NDI = l8Masked.map(createNDSI);
print('L8 + Indices', l8NDI);

//create a function to look over imagery and only select the most snow free images,
//this is to account for early snowfall and filter out those images with excess snow
    ///////This can get wonky. If you have just a few images it may be easier to visualize them and manually select images.
//this function will count the number of snow free pixels
var NDSIth = function(image){
  var getNDSI = image.select('NDSI').lte(0.4).selfMask().rename('NDSIth'); //<- take the NDSI and look for pixels over a threshold value
  var pixelCount = getNDSI.reduceRegion({reducer: ee.Reducer.count(), geometry: watershed.geometry(), scale: 30, bestEffort: true, maxPixels: 6700000});//<- count high NDSI pixels
  return image.addBands(getNDSI).set('NDSIcount', pixelCount.get('NDSIth')); //<- add the count of snowy pixels to imagery
};

//map the function to get the count of pixels that are snow over the image collection
var l8SnowCount = l8NDI.map(NDSIth);
//print('l8 w snowy pixel count', l8SnowCount);

//this function will pass over the image collection and only keep images with a defined number of 
//snow free pixels
//You should calculate a rough estimate of how much snow you should have based off of watershed area and imagery spatial resolution
var l8SnowFree = l8SnowCount.filter(ee.Filter.lte('NDSIcount', 2100000));//<- kick out images with a snowy pixel count higher than what you decide is necessary
l8SnowFree = l8SnowFree.select('B2', 'B3', 'B4', 'B5', 'B6', 'B7', //^ be careful, you can easily over/under estimate your threshold here
  'elevation', 'slope', 'aspect', 'NDSI', 'NDVI', 'EVI');
print('l8 snow free images', l8SnowFree);



print('Everything Above Here ^^^ Is Checking Your Data Preparation');
 ////////////////////////////////////Hopefully you don't have any errors yet!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
/////////////////////////////////////////Data is ready to classify now!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\



//create an empty list to add accuracies to after classification
var accuraciesL8 = ee.List([]); //<- this will create a list of your classification accuracy at the end

//This takes imagery after prep for each year out of the collection and uses a median pixel value to 
//create a single composite image, regardless of there being multiple images in a year or just one
var composite2014 = l8SnowFree.filter(ee.Filter.date('2014-01-01', '2014-12-31')).median();
print('2014 image composite', composite2014);
var composite2015 = l8SnowFree.filter(ee.Filter.date('2015-01-01', '2015-12-31')).median();
print('2015 image composite', composite2015);
var composite2016 = l8SnowFree.filter(ee.Filter.date('2016-01-01', '2016-12-31')).median();
print('2016 image composite', composite2016);
var composite2017 = l8SnowFree.filter(ee.Filter.date('2017-01-01', '2017-12-31')).median();
print('2017 image composite', composite2017);
var composite2018 = l8SnowFree.filter(ee.Filter.date('2018-01-01', '2018-10-15')).median();
print('2018 image composite', composite2018);
var composite2019 = l8SnowFree.filter(ee.Filter.date('2019-01-01', '2019-12-31')).median();
print('2019 image composite', composite2019);
var composite2020 = l8SnowFree.filter(ee.Filter.date('2020-01-01', '2020-09-30')).median();
print('2020 image composite', composite2020);
var composite2021 = l8SnowFree.filter(ee.Filter.date('2021-01-01', '2021-12-31')).median();
print('2021 image composite', composite2021);
var composite2022 = l8SnowFree.filter(ee.Filter.date('2022-01-01', '2022-12-31')).median();
print('2022 image composite', composite2022);
var composite2023 = l8SnowFree.filter(ee.Filter.date('2023-01-01', '2023-12-31')).median();
print('2023 image composite', composite2023);
var composite2024 = l8SnowFree.filter(ee.Filter.date('2024-01-01', '2024-10-10')).median();
print('2024 image composite', composite2024);
/////////This is a good place to start adding images to the map to see how things look
//Map.addLayer(composite2016, l8VisParams, 'L8 Composite Image: 2016')


////Export a composite image to an asset if you want a reference image saved somewhere
//Export.image.toAsset({
//  image: composite2021,     //<- make sure your years match
//  assetId: 'composite2021', //<- make sure your years match
//  region: watershed.geometry(),
//  scale: 30,
//  crs: 'EPSG:32606',
//  description: 'Composite2021ExportToAsset'
//});

/////////////////////////////////////MOVING INTO CLASSIFICATION PHASE, MAKE SURE YOUR TRAINING DATA ARE SET\\\\\\\\\\\\\\\\\\\\\\


//Introduce Classes feature collection for the classification. 
//Class numbers are determined in the Training Data script
//Classes in this case are: 1: Snow and Ice, 2: Bare Rock,
//3: Forest, 4: Shrub, 5: Heather Tundra, 6: Forbs tundra

//Notice we have no class 0 (water), and we have it masked out earlier
//Remove this if you are classifying water
//You may have a different number of classes for analysis, this is where you would edit those numbers.
var classesNW = classes.filter(ee.Filter.inList('Class', [1, 2, 3, 4, 5, 6])); //<- making sure water is gone
print('classes w water', classes);     //<- print both w and w/o water to check differences
print('classes w/o water', classesNW); //<- print both w and w/o water to check differences

//create a label for use in the classifier
var label = 'Class';

////This is an optional step for playing with how much training data you are using in your classification
////Use these lines to alter the amount of data you are supplying to the model and insert as variables in the function below
//var reducedTraining = classesNW.filter(ee.Filter.lte('random', 0.99)); //<- change this number (must be <1) to set the percent of TD
//                                                                      //to feed to the classifier


//define the important bands to use in the classification 
var bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'elevation', //<adjust these as needed, here is spectral, topo, and indices
  'slope', 'aspect', 'NDSI', 'NDVI', 'EVI'];
  


////////////////////////////CLASSIFYING FUNCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\  
//This is the big function where the magic happens
//Here is a general walkthrough:
  //1: split the training data into 80% training, 20% testing
  //2: sample the imagery under training data
  //3: create the classifier (random forest, svm, maxEnt, NN, etc.)
  //4: generate some stats of the classifier
  //5: get the classified images
  //6: test data for misclassified regions and accuracy
  //7: print confusion matrix
  //8: more stats generation
  //9: export images and the stats as needed

//////////////////A whole thesis in less than 10 steps!!\\\\\\\\\\\\\\\\\\\\\\\\\\\

function classifyDataL8(image, points, year) {
  //this will split the classes into training and testing data
  //rule of thumb to start with 80/20 and adjust as needed
  var trainingPoints = points.filter(ee.Filter.lte('random', 0.8)); //<- take all points with random column less than 0.8
  var validationPoints = points.filter(ee.Filter.gt('random', 0.8));//<- take all points with random column greater than 0.8
                                                                /////^^we are assuming normal distribtuion in random generation^^\\\\  

  var NDVI = image.select('NDVI'); //<- assign out indices if you want to view them later
  var EVI = image.select('EVI');
  
  //sample the training data over the imagery
  var training = image.reduceRegions({ //<- set up a sampling method with reducers
    collection: trainingPoints, //<- which training data are we using?
    reducer: ee.Reducer.first(),//<- how should we reduce for sampling?
    scale: 30                   //<- what is our input spatial resolution?
  }).filter(ee.Filter.neq('B1', null)).filter(ee.Filter.neq('B2', null))    //-------
  .filter(ee.Filter.neq('B3', null)).filter(ee.Filter.neq('B4', null))      //      |
  .filter(ee.Filter.neq('B5', null)).filter(ee.Filter.neq('B6', null))      //      |<- ignore any missing training points
  .filter(ee.Filter.neq('B7', null))                                        //      |
  .filter(ee.Filter.neq('NDVI', null)).filter(ee.Filter.neq('NDSI', null)); //-------
  
  //create and train an empty classifer
  var classifier = ee.Classifier.smileRandomForest(500) //<- pick a classifier and create an empty version: You have lots of options in GEE
  .train({                    //<- train the model with necessary inputs
    features: training,       // <- pick your features
    classProperty: 'Class',   // <- use the label that the data contain to assign training information
    inputProperties: image.bandNames() //<- use the input image's band names as inputs for training
  });
  
  //get classifier expanations
  var importance = ee.Dictionary(classifier.explain()// <- get importance of each input variable to the classification
  .get('importance', 'outOfBagErrorEstimate'));     //<- comes out as a percentage
  
  //print('importance ' + year, importance); //<-- print out the importance if you want to view it
  
  var totalImportance = importance.values().reduce(ee.Reducer.sum()); //<- should be 1 (100%)
  
  var importancePercentage = importance.map(function (band, importance) {
  return ee.Number(importance).divide(totalImportance).multiply(100)}); 
  
  print('importance Percentage ' + year, importancePercentage); //<- more of the same
  
  //classify the images
  var classifiedImage = image.classify(classifier); //<- run the classifier over an input image
  
  var classedVisParams = {min: 1, max: 6, 
  'palette': ['E0E0E0', '45414E', '0E5B07', 'CE6C47', 'FFC145', 'E14607'] //<- visualization for the classified images
  };
  
  //add the classified layer to the map
  Map.addLayer(classifiedImage, classedVisParams, 'L8 ' + year, 0); //<- check out what you've made!
  
  //use the map to get accuracy metrics from validation data created earlier
  var testing = classifiedImage.sampleRegions({ //<- let's see what it missed
    collection: validationPoints,     //<- input testing data
    properties: ['Class'],            //<- what property are we using?
    scale: 30,                        //<- input imagery resolution
    geometries: true        //<- true preserves the spatial information, false reports just values with no geolocation    
  });
  
  
  //find out which points are misclassified and display them
  var misclassified = testing.filter(ee.Filter.notEquals({ 
    leftField: 'Class', rightField: 'classification' //<- find where the classification and testing data DON'T line up
  }));
  var pointStyle = ee.Dictionary({
    1: {color: 'red', fillColor: 'E0E0E0', pointShape: 'circle', pointSize: 5},
    2: {color: 'red', fillColor: '45414E', pointShape: 'circle', pointSize: 5},
    3: {color: 'red', fillColor: '0E5B07', pointShape: 'circle', pointSize: 5},
    4: {color: 'red', fillColor: 'CE6C47', pointShape: 'circle', pointSize: 5}, //<- visualize misclassifications
    5: {color: 'red', fillColor: 'FFC145', pointShape: 'circle', pointSize: 5},
    6: {color: 'red', fillColor: 'E14607', pointShape: 'circle', pointSize: 5},
  });
  misclassified = misclassified.map(function(feature){
    return feature.set('style', pointStyle.get(feature.get('Class'))); //<- make the miscalssed points pretty
  });
  //print('Misclassified Points ' + year, misclassified);
  Map.addLayer(misclassified.style({styleProperty: 'style'}), null, 'Misclassified Points ' + year, 0); //<- add missclasses to map as dots
  
  //create a confusion matrix for the data
  var testingConfusionMatrix = testing.errorMatrix('Class', 'classification'); //<- create a classifier confusion matrix
  //print the matrices
  print('confusion matrix l8 ' + year, testingConfusionMatrix); //<- whole matrix
  print('test accuracy l8 ' + year, testingConfusionMatrix.accuracy()); //<- overall accuracy
  print('Users Accuracy '+year, testingConfusionMatrix.consumersAccuracy()); //<- user's accuracy (on the ground reliability)
  print('Producers Accuracy '+year, testingConfusionMatrix.producersAccuracy());// <- producer's accuracy (how often the map is accurate)
  print('Kappa '+year, testingConfusionMatrix.kappa()); //<- kappa score
  
  var accuracy = testingConfusionMatrix.accuracy(); //<- get the overall accuacy as a number
  accuraciesL8 = accuraciesL8.add(accuracy); //<- append accuracy to a list to track accuracy over time
  
  ////print in the console the area in square meters of the each class in the image
  ////This one is optional and takes a while to work, it's helpful but I would comment it out if you don't need it
  //var classArea = ee.Image.pixelArea().addBands(classifiedImage).divide(1e6)
  //                .reduceRegion({
  //                  reducer: ee.Reducer.sum().group(1),
  //                  geometry: watershed.geometry(),
  //                  scale: 30
  //                });
  //print('Pixel area of each class (km2) '+year, classArea);
  ////convert classArea to a feature
  //var classAreaFeature = ee.Feature(null, classArea);
  //print('class area feature', classAreaFeature);
  

  //This step exports the error matrix to your Drive, it has to undergo some transformation first
  //this step converts the error matrix into an array, and then a callable feature
  var exportMatrix = ee.Feature(null, {matrix: testingConfusionMatrix.array()});
  Export.table.toDrive({
    collection: ee.FeatureCollection(exportMatrix),
    description: 'L8_Confusion_Matrix_for_' + year,
    folder: 'ErrorMatrix',
    fileNamePrefix: 'L8_Confusion_Matrix_for_' + year,
    fileFormat: 'CSV'
  });
  
  //Now we can export the classified image to your Drive
  //export imagery to google drive
  Export.image.toDrive({
    image: classifiedImage, //<- image we want out
    description: 'L8_Classified_Image' + year, //<- task description
    folder: 'ClassifiedImageGEEOutputs', //<- where it should go
    fileNamePrefix: 'L8ClassImg_6class' + year + '_DEC16_2024', //<- Filename
    scale: 30, //<- resolution
    fileFormat: 'GeoTIFF', //<-format
    region: watershed.geometry(), //<- what area in the image to export
    crs: 'EPSG:32606' //<- reference system for geolocation
  });
  
  //export ndvi to google drive
  Export.image.toDrive({
    image: NDVI,
    description: 'L8_NDVI' + year,
    folder: 'ClassifiedImageGEEOutputs',
    fileNamePrefix: 'L8NDVI' + year,      //<- See comments above
    scale: 30,
    fileFormat: 'GeoTIFF',
    region: watershed.geometry(),
    crs: 'EPSG:32606'
  });
  
  //Export a classified image to an asset
  //This is helpful if you are continually referencing an image in other codes
  Export.image.toAsset({
    image: classifiedImage,
    description: 'classified' + year + 'toAsset',
    assetId: 'NJclassified' + year,
    region: watershed.geometry(),
    scale: 30,
    crs: 'EPSG:32606'
  });


/////////Feel free to comment out exports that you don't need, and you only need to run the ones you out of GEE for further processing\\\\\\\\\
}


//run the classifier function on the composited imagery from each year,
//outputs an image on the map of the classification as well as a confusion
//matrix and accuracy in the console. Also adds in the corresponding year's composited Landsat image 
Map.addLayer(composite2014, l8visParams, 'Landsat 8 2014', 0);
classifyDataL8(composite2014, classesNW, '2014');
Map.addLayer(composite2015, l8visParams, 'Landsat 8 2015', 0);
classifyDataL8(composite2015, classesNW, '2015');
Map.addLayer(composite2016, l8visParams, 'Landsat 8 2016', 0);
classifyDataL8(composite2016, classesNW, '2016');
Map.addLayer(composite2017, l8visParams, 'Landsat 8 2017', 0);
classifyDataL8(composite2017, classesNW, '2017');
Map.addLayer(composite2018, l8visParams, 'Landsat 8 2018', 0);
classifyDataL8(composite2018, classesNW, '2018');
Map.addLayer(composite2019, l8visParams, 'Landsat 8 2019', 0);
classifyDataL8(composite2019, classesNW, '2019');
Map.addLayer(composite2020, l8visParams, 'Landsat 8 2020', 0);
classifyDataL8(composite2020, classesNW, '2020');
Map.addLayer(composite2021, l8visParams, 'Landsat 8 2021', 0);
classifyDataL8(composite2021, classesNW, '2021');
Map.addLayer(composite2023, l8visParams, 'Landsat 8 2023', 0);
classifyDataL8(composite2023, classesNW, '2023');
Map.addLayer(composite2024, l8visParams, 'Landsat 8 2024', 0);
classifyDataL8(composite2024, classesNW, '2024');


////////YOU DID IT, IMAGERY IS CLASSIFIED\\\\\\\\\\\\\\\\\\
//You can repeat this script for different Landsat Satellites by altering input variables at the top
//You will also need to update your training data to match the satellite you are analyzing

//This creates an list of years to plot against accuracy to see how your accuracy changes over time with different images
//make sure you only input years that you have imagery
var listOfYearsL8 = ['2014', '2015', '2016', '2017', '2018', '2019','2020','2021', '2023', '2024']; //<- list of years
print('list of accuracies Landsat 8', accuraciesL8);
var accuracyChartL8 = ui.Chart.array.values({array: accuraciesL8, axis: 0, xLabels: listOfYearsL8}) //<- chart your accuracy 
                    .setOptions({title: 'Accuracy of Classification Over Time'});
print('accuracy chart L8', accuracyChartL8);


///////////////////NOW BEGINS ANALYSIS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
//GEE is not great (or intuitive) at running vector and table data\\
//move your imagery into your favorite GIS for easier interpretation\\
//we have created projects in ArcPRO and in R studio\\


///////////////////////////////////////////////////////////////////////////////////////////////////////
/////////////////Srcipt written while listening to:               ////////             |\                         
////////////////The Elder Scrolls V: Skyrim: OST by Jeremy Soule  ////////             | \                        
////////////////Rebirth - Greatest Hits by Old Gods of Asgard     ////////    (`````)  |  \                              
////////////////Inside by Bo Burnham                              ////////   (|||||||) |  {                         
////////////////Another Day Another Time by Various Artists       ////////  {|||||||||}|                          
////////What were you listening to??\\\\\\\\\\\\\\\\\\\\\\\\\\\   ////////   (|||||||)
//                                                                ////////    (,,,,,)
